import pandas as pd
from sqlalchemy import create_engine, text
import numpy as np
# NEW: Import os and dotenv to handle environment variables
import os
from dotenv import load_dotenv
# NEW: Import the Flask app and db object to create tables
from app import app, db

load_dotenv() # ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .env

# ==============================================================================
# * 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ DATABASE ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
# ==============================================================================
# **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
DB_USER = os.environ.get('DB_USER', 'root')
DB_PASSWORD = os.environ.get('DB_PASSWORD') # <-- * ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å .env
DB_HOST = os.environ.get('DB_HOST', 'localhost')
DB_NAME = os.environ.get('DB_NAME', 'loan_system')

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if not DB_PASSWORD:
    raise ValueError("‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ DB_PASSWORD ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")

db_connection_str = f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}'
db_engine = create_engine(db_connection_str)


# ==============================================================================
# 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ)
# ==============================================================================
def process_dataframe_and_import(df, table_name, column_map, source_name):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"""
    try:
        print(f"  - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å '{source_name}' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á '{table_name}'...")
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        df.rename(columns=column_map, inplace=True)

        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô column_map ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡∏¥‡∏ô
        # ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô KeyError ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô map ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô df
        valid_columns = [col for col in column_map.values() if col in df.columns]
        df = df[valid_columns]

        if table_name == 'customer_records' and 'customer_id' in df.columns:
            # --- REVISED: Generate PID-xxxx style IDs for missing values ---
            id_counter = 1001
            
            def generate_pid(value):
                # Check if the value is missing (NaN, None, or empty string)
                if pd.isna(value) or str(value).strip() == '':
                    nonlocal id_counter
                    new_id = f"PID-{id_counter}"
                    id_counter += 1
                    return new_id
                # If the value exists, keep it as is.
                return str(value).strip()

            df['customer_id'] = df['customer_id'].apply(generate_pid)

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
        for col in df.columns:
            if 'amount' in col or 'balance' in col or 'limit' in col or 'interest' in col or 'fee' in col:
                df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '', regex=False), errors='coerce').fillna(0)
            if 'date' in col or 'timestamp' in col:
                df[col] = pd.to_datetime(df[col], errors='coerce')
            elif 'time' in col: # NEW: Handle time columns
                df[col] = pd.to_datetime(df[col], errors='coerce', format='%H:%M:%S').dt.time

        df.replace({np.nan: None, 'NaT': None}, inplace=True)

        # Since we are now dropping and creating tables, the TRUNCATE logic is no longer needed.
        # We can directly append to the newly created empty tables.

        df.to_sql(table_name, con=db_engine, if_exists='append', index=False)
        print(f"  ‚úÖ ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏π‡πà‡∏ï‡∏≤‡∏£‡∏≤‡∏á '{table_name}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    except Exception as e:
        print(f"  ‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• '{source_name}' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á '{table_name}': {e}")


# ==============================================================================
# * 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤
# ==============================================================================

# --- 1. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö customer_records ---
customer_records_map = {
    'Timestamp': 'timestamp', 'Customer ID': 'customer_id', '‡∏ä‡∏∑‡πà‡∏≠': 'first_name', '‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•': 'last_name',
    '‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô': 'id_card_number', '‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠': 'mobile_phone', '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å': 'main_customer_group',
    '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏¢‡πà‡∏≠‡∏¢': 'sub_profession_group', '‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏¢‡πà‡∏≠‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ': 'other_sub_profession', '‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô': 'is_registered',
    '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏¥‡∏à‡∏Å‡∏≤‡∏£': 'business_name', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà': 'province', '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô': 'registered_address',
    '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': 'status', '‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£': 'desired_credit_limit', '‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥': 'approved_credit_limit',
    '‡πÄ‡∏Ñ‡∏¢‡∏Ç‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á': 'applied_before', '‡πÄ‡∏ä‡πá‡∏Ñ': 'check_status', '‡∏Ç‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ó‡∏≤‡∏á‡πÑ‡∏´‡∏ô': 'application_channel',
    '‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô': 'assigned_company', '‡∏´‡∏±‡∏Å‡∏î‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢': 'upfront_interest_deduction', '‡∏Ñ‡πà‡∏≤‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£': 'processing_fee', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤': 'application_date',
    '‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡πÇ‡∏•‡πÄ‡∏Ñ‡∏ä‡∏±‡πà‡∏ô‡∏ö‡πâ‡∏≤‡∏ô': 'home_location_link', '‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡πÇ‡∏•‡πÄ‡∏Ñ‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô': 'work_location_link', '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏': 'remarks',
    'Image URLs': 'image_urls', 'Logged In User': 'logged_in_user', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏±‡∏î‡∏ï‡∏£‡∏ß‡∏à': 'inspection_date',
    '‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏±‡∏î‡∏ï‡∏£‡∏ß‡∏à': 'inspection_time', '‡∏ú‡∏π‡πâ‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à': 'inspector'
}

# --- 2. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö approove ---
approvals_map = {
    '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': 'status', 'Customer ID': 'customer_id', '‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•': 'full_name', '‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå': 'phone_number',
    '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥': 'approval_date', '‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥': 'approved_amount', '‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô': 'assigned_company',
    '‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô': 'registrar', '‡∏£‡∏π‡∏õ‡∏ñ‡πà‡∏≤‡∏¢‡∏™‡∏±‡∏ç‡∏ç‡∏≤': 'contract_image_urls'
}

# --- 3. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bad_debt_records ---
bad_debt_map = {
    'Timestamp': 'timestamp', 'CustomerID': 'customer_id', 'CustomerName': 'customer_name', 'Phone': 'phone',
    'ApprovedAmount': 'approved_amount', 'OutstandingBalance': 'outstanding_balance', 'MarkedBy': 'marked_by', 'Notes': 'notes'
}

# --- 4. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pull_plug_records ---
pull_plug_map = {
    'Timestamp': 'timestamp', 'CustomerID': 'customer_id', 'CustomerName': 'customer_name', 'Phone': 'phone',
    'PullPlugAmount': 'pull_plug_amount', 'MarkedBy': 'marked_by', 'Notes': 'notes'
}

# --- 5. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö return_principal_records ---
return_principal_map = {
    'Timestamp': 'timestamp', 'CustomerID': 'customer_id', 'CustomerName': 'customer_name', 'Phone': 'phone',
    'ReturnAmount': 'return_amount', 'MarkedBy': 'marked_by', 'Notes': 'notes'
}

# --- 6. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö allpidjob ---
all_pid_jobs_map = {
    'Date': 'transaction_date', 'CompanyName': 'company_name', 'CustomerID': 'customer_id', 'Time': 'transaction_time',
    'CustomerName': 'customer_name', 'interest': 'interest', 'Table1_OpeningBalance': 'table1_opening_balance',
    'Table1_NetOpening': 'table1_net_opening', 'Table1_PrincipalReturned': 'table1_principal_returned',
    'Table1_LostAmount': 'table1_lost_amount', 'Table2_OpeningBalance': 'table2_opening_balance',
    'Table2_NetOpening': 'table2_net_opening', 'Table2_PrincipalReturned': 'table2_principal_returned',
    'Table2_LostAmount': 'table2_lost_amount', 'Table3_OpeningBalance': 'table3_opening_balance',
    'Table3_NetOpening': 'table3_net_opening', 'Table3_PrincipalReturned': 'table3_principal_returned',
    'Table3_LostAmount': 'table3_lost_amount', '‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô': 'main_assigned_company'
}

# --- 7. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö users ---
users_map = {
    'id': 'id',      # Key ‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô CSV, Value ‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á SQL
    'pass': 'password'
}

def main():
    # --- Step 0: Create tables first ---
    # This function is now defined in the provided `migrate_data.py` but not shown here for brevity.
    # It drops and creates all tables.
    # create_tables() is assumed to be called here.

    # --- Step 1: Import main customer data from data1.csv ---
    customer_csv_path = 'data1.csv'
    print(f"\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏´‡∏•‡∏±‡∏Å: '{customer_csv_path}'")
    try:
        # Define dtypes to prevent pandas from dropping leading zeros from phone numbers and ID cards
        customer_dtype_spec = {'‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠': str, '‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô': str}
        df_customers = pd.read_csv(customer_csv_path, encoding='utf-8-sig', dtype=customer_dtype_spec)
        process_dataframe_and_import(df_customers, 'customer_records', customer_records_map, f"‡πÑ‡∏ü‡∏•‡πå '{customer_csv_path}'")
    except FileNotFoundError:
        print(f"üö® ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{customer_csv_path}'! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå '{customer_csv_path}': {e}")

    # --- Step 2: Import user data from users.csv ---
    users_csv_path = 'users.csv'
    print(f"\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV: '{users_csv_path}'")
    try:
        df_users = pd.read_csv(users_csv_path, encoding='utf-8-sig')
        process_dataframe_and_import(df_users, 'users', users_map, f"‡πÑ‡∏ü‡∏•‡πå '{users_csv_path}'")
    except FileNotFoundError:
        print(f"üö® ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{users_csv_path}'!")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå '{users_csv_path}': {e}")

    print("\nüéâ ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

if __name__ == '__main__':
    main()